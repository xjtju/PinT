; PinT configuration file, 
; thanks to .INI parser https://github.com/benhoyt/inih  
;
; There are not any assumptions about the measurement unit standard for all the physical variables used in the program. 
; You must be careful to make sure the physical UNIT consistency for specific problem. 
;
; For test time  parallel only, set all the directions of space division to ONE (spnumx/y/z);
; For test space parallel only, set the time division to ONE (tsnum); 
; For test single process serial performance, set all time-space divisions to ONE, or set the 'test_serial' to ONE for convience 

[domain]         ; time-space domain of the problem   
ndim =  3        ; dimension number : 1,2,3. if ndim is not THREE, the unused dimension parameters will be ignored automacally
                 ; NOTE:
                 ; In some special rare cases, deteriorated dimensions may occur, 
                 ; for 3D example, when using 2 cores to divide Z directions with only 2 cell-height,
                 ; the divided grid will become (deteriorate to) 2D (Z height is ONE).
                 ; the program can not be able to deal this situation correctly. 

Tspan = 0.1     ; time domain 
Nt = 20000          ; the time steps of the whole time domain serially if using fine solver

Xspan = 1      ; space domain, geographical size  
Yspan = 1 
Zspan = 1 

Nx = 50       ; the whole grid space size, all discrete cell numbers. 
Ny = 50       ; NOTE: 
Nz = 50       ; the size of each dimension not includes the most outer guard cells(border) outside the geographical domain,, 
             ; the framework will automacally create the proper border cells outside the space domain,
             ; and the size must be well divided (no remainders left) by the corresponding CPU cores assinged to the direction, 
             ; otherwise, the calculated result may be incorrect, alghough the program may be normally converged. 
nguard  = 1     ;  the nguard cell number 

bc_type = 1      ;  boundary type. 
                 ;    0: Dirichlet, constant value, default is ZERO; 
                 ;    1: homogeneous Neumann, U_{n+1} = U_{n}
                 ;    2: customized 
bc_val  = 0.0    ;  valid only when bc_type=0

                  ; more control of boundary conditions, will overwrite the above general setttings 
bc_type_xl = 0    ; left  x boundary 
bc_type_xr = 0    ; right x boundary 
;bc_type_yl = 1    ; left  y boundary, front 
;bc_type_yr = 1    ; right y boundary, back 
;bc_type_zl = 1    ; left  z boundary, down(bottom)  
;bc_type_zr = 1    ; right z boundary, upper 
bc_val_xl  = 1.0  ; value of left x 
bc_val_xr  = 0.0  ; value of right x  
;bc_val_yl  = 0.0  ;  
;bc_val_yr  = 0.0  ;  
;bc_val_zl  = 0.0  ;  
;bc_val_zr  = 0.0  ;  

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
[parareal]      ; PinT control parameter
                ; Assert( tsnum * spnumx * spnumy * spnumz EQUALS the number of MPI processes ) 
tsnum  = 1      ; the number of time partitions(slices), parallel processes along time domain 
                
spnumx = 1      ; the number of space partitions (CPU cores) in one time slice, x direction  
spnumy = 1      ; y direction
spnumz = 1      ; z direction

pipelined  = 0        ; pipeline Parareal is used or not, default is ZERO (not used) 
kpar_limit = 99       ; for pipeline mode only, synchonization mode is the same with the time slices  
skip_mode  = 1        ; skip the previous time slices which fine solver has already evolved over.  Default value is ZERO (not skip). 
                      ; It will skip useless network communication(send/recv) only (not including calculation) for current time slice, 
                      

relax_factor = 1.0    ; the relaxation factor to speed up the convergency, it should be less than 1.0.
                      ; default value is ONE (no relaxation), details at [Shulin Wu, 2009, Parareal-Richardson Algorithm] 
                      ; NOT yet activated at current version

rfc_ = 100           ; fine steps / coarse steps, not the accuracy value of rfc in Parareal 

converge_eps = 1.0e-6 ; parareal convergency error limit 

sml_res = 1.0e-36   ; the threshold for residual control. Due to the "Machine Epsilon" or rounding error, 
                    ; Sometimes, according to the parareal algorithm, 
                    ; the residual should be ZERO at the end of certain tima slice 
                    ; where fine solver has already continuously evolved over all the time slice before and including it, 
                    ; but in practice, the calculation value is not ZERO, 
                    ; despite it is very small, it will has an unignorable impact on convergency due to  accumulating effect.
                    ; when residual is less than the threshold, res is regarded as ZERO.

[linear_solver]       ; the default setttings for linear solver
                      ; If there are multiple instances of solver without different setttings, you have to manually control them.
ls_solver = 0         ; default linear solver, 0: BiCG; 1: SOR; >1: NULL. In practice, BiCG is more efficient than SOR
ls_itmax = 30         ; linear solver's max iteration number
ls_eps   = 1.0e-6     ; linear solver's convergency error limit 
ls_abort = 0          ; when convergency condition is not satified, exit main program or not 
ls_precond = 0        ; use preconditioner or not
ls_relaxfactor = 1.4  ; the relaxation factor (omega) of SOR. 
                      ; NOTE : the parameter controls both SOR as an independent solver or a preconditioner 
                      ;   for the pfm example, the proper value is 1.4
                      
ls_eps_dynamic = 1    ; use dynamic eps or not, in order to reduce the useless iterations of linear_solver within the Newton solver  
ls_eps_factor  = 1.2  ; dynamic eps decreasing factor  

[monitor]
debug_pre   = euler ; output file name prefix for debug or other uses. 8 chars limit.
                    ; all result data of the whole space domain can be aggregated and written into the file,
                    ; but at the current version, only pure text format is supported. 
                    ; so it is not recommended for dumping out large data of massive runnings 
                    ; the output file name will be [debug_pre].[mytid].[mysid].txt for local, and [debug_pre].[mytid].all.txt for global
                    ; mytid is the current time slice id ; mysid is the space division id of the current time slice.
                    ; for easy to debug by human eyes, the recommended resolution is below 10^3 cells at small running  

with_coord = 0      ; ASCII-format output with coordinates or not, default is 'true(1)', used only for grid inner variables 
monitor_pre = prof  ; the prefix of performance data file name. 8 chars limit. 
verbose     = 0     ; output some debugging info during running

test_serial = 0     ; A fast switch for only run the program in serial mode to measure the orininal single process performance.
                    ; Of coarse, you can do this by manually setting all related time-space parallel parameters  
                    ; NOTE: if the flag is valid, all the parameters related with time-space parallel will be ignored.
                    ; The parameter only guarantees that there is one MPI process, but puts no limitation on OpenMP threads.  
                    ; default is ZERO
                    
dump_init   = 0     ; ouput the initial values for debugging before starting, defalut is ZERO   

;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;
[pfm]                ; problem-specific configuration is also supported.

fsolver = 2          ; Fine solver:   0: CN (default); 1: BD4 ; 2 : Forward Euler (be careful, unstable )
csolver = 1          ; Coarse solver: 0: CN          ; 1: BD4 ; 
newton_itmax = 100   ; the max iterations of Newton's Method
theta = 0.5          ; 0.5: Crank-Nicolson; 0: Ex.Euler; 1: Im.Euler (be careful, Ex.Euler is unstable) 

ac_dval = 1          ; Allen-Cahn equation, diffuse coefficient 
ac_kval = 1600       ; related with the gradient of potential energy
;ac_kval = 0     
ac_beta = 0          ; beta=0, quickly reach the steady state without any movement  
ac_beta = -0.128    ; left moving, if negative number, make sure no blank between the minus/- and number itself 
